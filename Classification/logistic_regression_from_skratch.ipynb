{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46205/1856754905.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.623660</td>\n",
       "      <td>78.024693</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.286711</td>\n",
       "      <td>43.894998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.847409</td>\n",
       "      <td>72.902198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.182599</td>\n",
       "      <td>86.308552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.032736</td>\n",
       "      <td>75.344376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>83.489163</td>\n",
       "      <td>48.380286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>42.261701</td>\n",
       "      <td>87.103851</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>99.315009</td>\n",
       "      <td>68.775409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>55.340018</td>\n",
       "      <td>64.931938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>74.775893</td>\n",
       "      <td>89.529813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1  2\n",
       "0   34.623660  78.024693  0\n",
       "1   30.286711  43.894998  0\n",
       "2   35.847409  72.902198  0\n",
       "3   60.182599  86.308552  1\n",
       "4   79.032736  75.344376  1\n",
       "..        ...        ... ..\n",
       "95  83.489163  48.380286  1\n",
       "96  42.261701  87.103851  1\n",
       "97  99.315009  68.775409  1\n",
       "98  55.340018  64.931938  1\n",
       "99  74.775893  89.529813  1\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "\n",
    "df = pd.read_csv(\n",
    "    r\"/home/ahmed/Ml-algorithms-from-scratch-and-scikit-learn-in-python-/DataSets/Data.csv\"\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((99, 2), (1, 2), (99,), (1,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features, tests = df[[\"0\", \"1\"]], df[\"2\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    features, tests, test_size=0.01, random_state=1\n",
    ")\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five elements in X_train are:\n",
      " [[80.366756   90.9601479 ]\n",
      " [52.04540477 69.43286012]\n",
      " [94.83450672 45.6943068 ]\n",
      " [74.49269242 84.84513685]\n",
      " [67.94685548 46.67857411]]\n",
      "Type of X_train: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"First five elements in X_train are:\\n\", x_train[:5])\n",
    "print(\"Type of X_train:\", type(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Sigmoid function :\n",
    "\n",
    "logistic regression model is represented as\n",
    "\n",
    "$$ f\\_{\\mathbf{w},b}(x) = g(\\mathbf{w}\\cdot \\mathbf{x} + b)$$\n",
    "\n",
    "function $g$ is the sigmoid function. The sigmoid function is defined as:\n",
    "\n",
    "$$g(z) = \\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "### 2 Cost function\n",
    "\n",
    "logistic regression, the cost function is of the form\n",
    "\n",
    "$$ J(\\mathbf{w},b) = \\frac{1}{m}\\sum*{i=0}^{m-1} \\left[ loss(f*{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) \\right] \\tag{1}$$\n",
    "\n",
    "where\n",
    "\n",
    "- m is the number of training examples in the dataset\n",
    "- $loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)})$ is the cost for a single data point, which is -\n",
    "\n",
    "  $$loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) = (-y^{(i)} \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) \\tag{2}$$\n",
    "\n",
    "### 3 gradient descent\n",
    "\n",
    "the gradient descent algorithm is:\n",
    "\n",
    "$$\\begin{align*}& \\text{repeat until convergence:} \\; \\lbrace \\newline \\; & b := b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b} \\newline       \\; & w_j := w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{1}  \\; & \\text{for j := 0..n-1}\\newline & \\rbrace\\end{align*}$$\n",
    "\n",
    "where, parameters $b$, $w_j$ are all updated simultaniously\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - \\mathbf{y}^{(i)}) \\tag{2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - \\mathbf{y}^{(i)})x_{j}^{(i)} \\tag{3}\n",
    "$$\n",
    "\n",
    "- m is the number of training examples in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logistic_regression:\n",
    "    def __init__(self, X, Y, W, B, alpha, iter):\n",
    "        self.x = X\n",
    "        self.y = Y\n",
    "        self.w = W\n",
    "        self.b = B\n",
    "        self.alpha = alpha\n",
    "        self.iter = iter\n",
    "        self.j_cost = []\n",
    "        self.parameters = []\n",
    "        return\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        g_z = 1 / (1 + np.exp(-z))\n",
    "        return g_z\n",
    "\n",
    "    # this fucntion calcualte w * x + b\n",
    "    def Z(self, i):\n",
    "        z = np.dot(self.x[i], self.w) + self.b\n",
    "        return z\n",
    "\n",
    "    def loss(self, f_wb, i):\n",
    "        Loss = -self.y[i] * np.log(f_wb) - (1 - self.y[i]) * np.log(1 - f_wb)\n",
    "        return Loss\n",
    "\n",
    "    def Cost_fucntion(self):\n",
    "\n",
    "        # number of samples\n",
    "        n = self.x.shape[0]\n",
    "        cost = 0\n",
    "        for i in range(n):\n",
    "\n",
    "            z = self.Z(i)\n",
    "            f_wb = self.sigmoid(z)\n",
    "\n",
    "            cost += self.loss(f_wb, i)\n",
    "\n",
    "        j_wb = cost / n\n",
    "\n",
    "        return j_wb\n",
    "\n",
    "    def derivative(self):  # fitting\n",
    "\n",
    "        n, m = self.x.shape\n",
    "        d_dw = np.zeros(self.w.shape)\n",
    "        d_db = 0\n",
    "\n",
    "        for i in range(n):\n",
    "            z = self.Z(i)\n",
    "            f_wb = self.sigmoid(z)\n",
    "\n",
    "            for j in range(m):\n",
    "                d_dw[j] = d_dw[j] + (f_wb - self.y[i]) * self.x[i][j]\n",
    "\n",
    "            d_db = d_db + (f_wb - self.y[i])\n",
    "        d_dw = d_dw / n\n",
    "        d_db = d_db / n\n",
    "\n",
    "        return d_dw, d_db\n",
    "\n",
    "    def fit(self):  # gradient_descent\n",
    "\n",
    "        j_cost = []\n",
    "        parameters = []\n",
    "\n",
    "        for i in range(self.iter):\n",
    "            d_dw, d_db = self.derivative()\n",
    "\n",
    "            w_temp = self.w - self.alpha * d_dw\n",
    "            b_temp = self.b - self.alpha * d_db\n",
    "\n",
    "            cost_now = self.Cost_fucntion()\n",
    "            self.j_cost.append(cost_now)\n",
    "            self.parameters.append([self.w, self.b])\n",
    "            self.w = w_temp\n",
    "            self.b = b_temp\n",
    "            if i % 100 == 0:\n",
    "                print(\n",
    "                    f\"Iteration {i:4}: Cost {float(self.j_cost[-1]):8.2f}   when w = {self.w} and b = {self.b}\"\n",
    "                )\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        prediction = []\n",
    "        f = []\n",
    "        n = len(x_test)\n",
    "        for i in range(n):\n",
    "            z = self.Z(i)\n",
    "            f_wb = self.sigmoid(z)\n",
    "            f.append(float(f_wb))\n",
    "            if f_wb > 0.5:\n",
    "                prediction.append(1)\n",
    "            else:\n",
    "                prediction.append(0)\n",
    "        return prediction, f\n",
    "\n",
    "    def accurece_score(self, x_prediction, y_test):\n",
    "\n",
    "        total_ture = 0\n",
    "        for i in range(len(y_test)):\n",
    "            if x_prediction[i] == y_test[i]:\n",
    "                total_ture += 1\n",
    "        precentage = total_ture / len(y_test) * 100\n",
    "        return precentage\n",
    "\n",
    "    def coef_(self):\n",
    "        return self.w\n",
    "\n",
    "    def intercet_(self):\n",
    "        return self.b\n",
    "\n",
    "    def cost_per_parameters(self):\n",
    "        for i in range(len(self.j_cost)):\n",
    "            print(\n",
    "                f\"Iteration {i:2}: Cost {float(self.j_cost[i]):8.2f}   when w = {self.parameters[i][0]} and b = {self.parameters[i][1]}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931471805599458\n"
     ]
    }
   ],
   "source": [
    "n = x_train.shape[1]\n",
    "\n",
    "log_reg = logistic_regression(x_train, y_train, np.zeros(n), 0, 0, 0)\n",
    "cost = log_reg.Cost_fucntion()\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004334414685248499"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.array([0.2, 0.2])\n",
    "b = -24.0\n",
    "model = logistic_regression(x_test, y_test, w, b, 0, 0)\n",
    "cost_mode = model.Cost_fucntion()\n",
    "cost_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = x_train.shape\n",
    "w_inti = 0.01 * (np.random.rand(2).reshape(-1, 1) - 0.5)\n",
    "b_inti = -8\n",
    "alpha = 0.001\n",
    "Iteration = 500\n",
    "logistic = logistic_regression(x_train, y_train, w_inti, b_inti, alpha, Iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost     4.65   when w = [[0.04356945]\n",
      " [0.04749264]] and b = [-7.99940444]\n",
      "Iteration  100: Cost     0.31   when w = [[0.0696391 ]\n",
      " [0.06340376]] and b = [-8.00105642]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46205/3600988982.py:79: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  f\"Iteration {i:4}: Cost {float(self.j_cost[-1]):8.2f}   when w = {self.w} and b = {self.b}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  200: Cost     0.31   when w = [[0.06965921]\n",
      " [0.063414  ]] and b = [-8.00298455]\n",
      "Iteration  300: Cost     0.31   when w = [[0.0696743 ]\n",
      " [0.06342923]] and b = [-8.00491203]\n",
      "Iteration  400: Cost     0.31   when w = [[0.06968937]\n",
      " [0.06344446]] and b = [-8.00683888]\n"
     ]
    }
   ],
   "source": [
    "logistic.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06970429],\n",
       "       [0.06345953]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.coef_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30765096]\n"
     ]
    }
   ],
   "source": [
    "print(logistic.Cost_fucntion())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99   99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46205/3600988982.py:89: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  f.append(float(f_wb))\n"
     ]
    }
   ],
   "source": [
    "pred, f = logistic.predict(x_train)\n",
    "pred\n",
    "print(len(pred), \" \", len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accurece score =  91.91919191919192\n"
     ]
    }
   ],
   "source": [
    "print(\"model accurece score = \", logistic.accurece_score(pred, y_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
