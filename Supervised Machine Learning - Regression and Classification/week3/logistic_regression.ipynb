{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.623660</td>\n",
       "      <td>78.024693</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.286711</td>\n",
       "      <td>43.894998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.847409</td>\n",
       "      <td>72.902198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.182599</td>\n",
       "      <td>86.308552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.032736</td>\n",
       "      <td>75.344376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>83.489163</td>\n",
       "      <td>48.380286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>42.261701</td>\n",
       "      <td>87.103851</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>99.315009</td>\n",
       "      <td>68.775409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>55.340018</td>\n",
       "      <td>64.931938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>74.775893</td>\n",
       "      <td>89.529813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1  2\n",
       "0   34.623660  78.024693  0\n",
       "1   30.286711  43.894998  0\n",
       "2   35.847409  72.902198  0\n",
       "3   60.182599  86.308552  1\n",
       "4   79.032736  75.344376  1\n",
       "..        ...        ... ..\n",
       "95  83.489163  48.380286  1\n",
       "96  42.261701  87.103851  1\n",
       "97  99.315009  68.775409  1\n",
       "98  55.340018  64.931938  1\n",
       "99  74.775893  89.529813  1\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "df = pd.read_csv(r'/home/ahmed/Ai/Machine learning from scratch/week2/Data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70, 2), (30, 2), (70,), (30,))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features, tests = df[['0', '1']], df['2']\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, tests, test_size=.3,random_state=1)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train) \n",
    "y_test = np.array(y_test)\n",
    "\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five elements in X_train are:\n",
      " [[49.07256322 51.88321182]\n",
      " [74.775893   89.5298129 ]\n",
      " [50.28649612 49.80453881]\n",
      " [83.48916274 48.3802858 ]\n",
      " [78.63542435 96.64742717]]\n",
      "Type of X_train: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"First five elements in X_train are:\\n\", x_train[:5])\n",
    "print(\"Type of X_train:\",type(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Sigmoid function :\n",
    "\n",
    "logistic regression model is represented as\n",
    "\n",
    "$$ f_{\\mathbf{w},b}(x) = g(\\mathbf{w}\\cdot \\mathbf{x} + b)$$\n",
    "\n",
    "function $g$ is the sigmoid function. The sigmoid function is defined as:\n",
    "\n",
    "$$g(z) = \\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "\n",
    "### 2 Cost function\n",
    "\n",
    "logistic regression, the cost function is of the form \n",
    "\n",
    "$$ J(\\mathbf{w},b) = \\frac{1}{m}\\sum_{i=0}^{m-1} \\left[ loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) \\right] \\tag{1}$$\n",
    "\n",
    "where\n",
    "* m is the number of training examples in the dataset\n",
    "* $loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)})$ is the cost for a single data point, which is - \n",
    "\n",
    "    $$loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) = (-y^{(i)} \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) \\tag{2}$$\n",
    "\n",
    "### 3 gradient descent\n",
    "\n",
    "the gradient descent algorithm is:\n",
    "\n",
    "$$\\begin{align*}& \\text{repeat until convergence:} \\; \\lbrace \\newline \\; & b := b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b} \\newline       \\; & w_j := w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{1}  \\; & \\text{for j := 0..n-1}\\newline & \\rbrace\\end{align*}$$\n",
    "\n",
    "where, parameters $b$, $w_j$ are all updated simultaniously\n",
    "$$\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - \\mathbf{y}^{(i)}) \\tag{2}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - \\mathbf{y}^{(i)})x_{j}^{(i)} \\tag{3}\n",
    "$$\n",
    "* m is the number of training examples in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logistic_regression:\n",
    "    def __init__(self, X, Y, W, B, alpha, iter):\n",
    "        self.x = X\n",
    "        self.y = Y\n",
    "        self.w = W\n",
    "        self.b = B  \n",
    "        self.alpha = alpha\n",
    "        self.iter = iter\n",
    "        self.j_cost = []\n",
    "        self.parameters = []\n",
    "        return\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        g_z = 1 / (1 + np.exp(-z))\n",
    "        return g_z        \n",
    "        \n",
    "    # this fucntion calcualte w * x + b\n",
    "    def Z(self, i):\n",
    "        z = np.dot(self.x[i], self.w) + self.b\n",
    "        return z\n",
    "\n",
    "    def loss(self, f_wb, i):\n",
    "        Loss = -self.y[i] * np.log(f_wb) - (1 - self.y[i]) * np.log(1 - f_wb)\n",
    "        return Loss\n",
    "    \n",
    "    def Cost_fucntion(self):\n",
    "        \n",
    "        # number of samples\n",
    "        n = self.x.shape[0]\n",
    "        cost = 0\n",
    "        for i in range(n):\n",
    "            \n",
    "            z = self.Z(i)\n",
    "            f_wb = self.sigmoid(z)\n",
    "\n",
    "            cost += self.loss(f_wb, i)\n",
    "            \n",
    "        j_wb = cost / n\n",
    "\n",
    "        return j_wb\n",
    "        \n",
    "        \n",
    "    def derivative(self): # fitting\n",
    "        \n",
    "        n, m = self.x.shape\n",
    "        d_dw = np.zeros(self.w.shape)\n",
    "        d_db = 0        \n",
    "\n",
    "        for i in range(n):\n",
    "            z = self.Z(i)\n",
    "            f_wb = self.sigmoid(z)            \n",
    "            \n",
    "            for j in range(m):\n",
    "                d_dw[j] = d_dw[j] + (f_wb - self.y[i]) * self.x[i][j]         \n",
    "            \n",
    "            d_db = d_db + (f_wb - self.y[i])\n",
    "        d_dw = d_dw / n\n",
    "        d_db = d_db / n\n",
    "\n",
    "        return d_dw, d_db\n",
    "\n",
    "\n",
    "    def fit(self): # gradient_descent\n",
    "        \n",
    "        j_cost = []\n",
    "        parameters = []\n",
    "        \n",
    "        for i in range(self.iter):\n",
    "            d_dw, d_db = self.derivative()\n",
    "\n",
    "            w_temp = self.w - self.alpha * d_dw\n",
    "            b_temp = self.b - self.alpha * d_db\n",
    "            \n",
    "            cost_now = self.Cost_fucntion()\n",
    "            self.j_cost.append(cost_now)\n",
    "            self.parameters.append([self.w, self.b])\n",
    "            self.w = w_temp\n",
    "            self.b = b_temp\n",
    "            if(i % 100 == 0):\n",
    "                print(f\"Iteration {i:4}: Cost {float(self.j_cost[-1]):8.2f}   when w = {self.w} and b = {self.b}\")\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        prediction = []\n",
    "        n = len(x_test)\n",
    "        for i in range(n):\n",
    "            z = self.Z(i)\n",
    "            f_wb = self.sigmoid(z)\n",
    "            if f_wb > .5:\n",
    "                prediction.append(1)\n",
    "            else:    \n",
    "                prediction.append(0)\n",
    "        return prediction\n",
    "    \n",
    "    def accurece_score(self, x_prediction, y_test):\n",
    "        \n",
    "        total_ture = 0\n",
    "        for i in range(len(y_test)):\n",
    "            if x_prediction[i] == y_test[i]:\n",
    "                total_ture += 1\n",
    "        precentage = total_ture / len(y_test) * 100\n",
    "        return precentage\n",
    "\n",
    "\n",
    "    def coef_(self):\n",
    "        return self.w\n",
    "    def intercet_(self):\n",
    "        return self.b\n",
    "    def cost_per_parameters(self):\n",
    "        for i in range(len(self.j_cost)):\n",
    "            print(f\"Iteration {i:2}: Cost {float(self.j_cost[i]):8.2f}   when w = {self.parameters[i][0]} and b = {self.parameters[i][1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931471805599454\n"
     ]
    }
   ],
   "source": [
    "n = x_train.shape[1]\n",
    "\n",
    "log_reg = logistic_regression(x_train, y_train, np.zeros(n), 0, 0, 0)\n",
    "cost = log_reg.Cost_fucntion()\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35869305283563985"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.array([0.2, 0.2])\n",
    "b = -24.\n",
    "model = logistic_regression(x_test, y_test, w, b,0,0)\n",
    "cost_mode = model.Cost_fucntion()\n",
    "cost_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = x_train.shape\n",
    "w_inti = 0.01 * (np.random.rand(2).reshape(-1,1) - 0.5)\n",
    "b_inti = -8\n",
    "alpha = .001\n",
    "Iteration = 500\n",
    "logistic = logistic_regression(x_train, y_train, w_inti, b_inti, alpha, Iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost     4.70   when w = [[0.04847268]\n",
      " [0.05271695]] and b = [-7.99937197]\n",
      "Iteration  100: Cost     0.27   when w = [[0.07436183]\n",
      " [0.06178906]] and b = [-8.00110107]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24764/3365210996.py:80: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(f\"Iteration {i:4}: Cost {float(self.j_cost[-1]):8.2f}   when w = {self.w} and b = {self.b}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  200: Cost     0.27   when w = [[0.07442351]\n",
      " [0.06176335]] and b = [-8.00307037]\n",
      "Iteration  300: Cost     0.27   when w = [[0.07443973]\n",
      " [0.06177835]] and b = [-8.00503908]\n",
      "Iteration  400: Cost     0.27   when w = [[0.07445573]\n",
      " [0.06179352]] and b = [-8.00700715]\n"
     ]
    }
   ],
   "source": [
    "logistic.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07447157],\n",
       "       [0.06180855]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.coef_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26990015]\n"
     ]
    }
   ],
   "source": [
    "print(logistic.Cost_fucntion())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70   70\n"
     ]
    }
   ],
   "source": [
    "pred = logistic.predict(x_train)\n",
    "pred\n",
    "print(len(pred), ' ', len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accurece score =  94.28571428571428\n"
     ]
    }
   ],
   "source": [
    "print('model accurece score = ', logistic.accurece_score(pred, y_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
