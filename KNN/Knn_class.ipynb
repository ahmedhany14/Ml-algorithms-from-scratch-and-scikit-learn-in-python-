{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# spliting tests\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# preprocessing and model piplines\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Models\n",
    "from sklearn.neighbors import (\n",
    "    KNeighborsClassifier,\n",
    "    RadiusNeighborsClassifier,\n",
    "    NeighborhoodComponentsAnalysis,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, Ridge, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    r\"/home/ahmed/Ml-algorithms-from-scratch-and-scikit-learn-in-python-/DataSets/diabetes.csv\"\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[\n",
    "    [\n",
    "        \"Pregnancies\",\n",
    "        \"Glucose\",\n",
    "        \"BloodPressure\",\n",
    "        \"SkinThickness\",\n",
    "        \"Insulin\",\n",
    "        \"BMI\",\n",
    "        \"DiabetesPedigreeFunction\",\n",
    "        \"Age\",\n",
    "    ]\n",
    "]\n",
    "tests = df[\"Outcome\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    features, tests, test_size=0.3, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "scaler = StandardScaler()\n",
    "log_reg = Pipeline([(\"StandardScaler\", scaler), (\"LogisticRegression\", model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test score =  77.92207792207793\n",
      "x_train score =  76.35009310986965\n"
     ]
    }
   ],
   "source": [
    "log_reg.fit(x_train, y_train)\n",
    "prediction = log_reg.predict(X=x_test)\n",
    "print(\"x_test score = \", log_reg.score(X=x_test, y=y_test) * 100)\n",
    "print(\"x_train score = \", log_reg.score(X=x_train, y=y_train) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors\n",
    "\n",
    "provides functionality for unsupervised and supervised neighbors-based learning methods, used with classification for data with discrete labels, and regression for data with continuous labels\n",
    "\n",
    "use a technique to find a predefined number of training samples closest in distance to the new point, and predict the label from these. The number of samples can be a user-defined constant (k-nearest neighbor learning), or vary based on the local density of points (radius-based neighbor learning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors Classification\n",
    "\n",
    "it does not attempt to construct a general internal model, but use the, but simply stores instances of the training data. Classification is computed from a simple majority vote of the nearest neighbors of each point: a query point is assigned the data class which has the most representatives within the nearest neighbors of the point.\n",
    "\n",
    "there is 2 different nearest neighbors classifiers: KNeighborsClassifier (KNC) implements learning based on the k nearest neighbors of each query point, where is an integer value specified by the user. RadiusNeighborsClassifier (RNC) implements learning based on the number of neighbors within a fixed radius r of each training point, where is a floating-point value specified by the user.\n",
    "\n",
    "### KNC\n",
    "\n",
    "implements learning based on the k nearest neighbors of each query point, and then assighn the label to the most voted label in tringing data set\n",
    "\n",
    "usally k = sqrt for n_samples\n",
    "\n",
    "### RNC\n",
    "\n",
    "implements learning based on the neighbors within a fixed radius r of the query point, where r is a floating-point value specified by the user.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) KNC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  23\n",
      "algorithm is  brute\n",
      "x_test score =  74.45887445887446\n",
      "x_train score =  76.35009310986965\n",
      "time taken =  0.030486106872558594\n",
      "\n",
      "\n",
      "k =  23\n",
      "algorithm is  kd_tree\n",
      "x_test score =  74.45887445887446\n",
      "x_train score =  76.35009310986965\n",
      "time taken =  0.011073827743530273\n",
      "\n",
      "\n",
      "k =  23\n",
      "algorithm is  ball_tree\n",
      "x_test score =  74.45887445887446\n",
      "x_train score =  76.35009310986965\n",
      "time taken =  0.0093231201171875\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "algorithms = [\"brute\", \"kd_tree\", \"ball_tree\"]\n",
    "\n",
    "for algo in algorithms:\n",
    "    start_time = time.time()\n",
    "    k = int(math.sqrt(len(x_train)))\n",
    "    if not (k & 1):\n",
    "        k += 1\n",
    "    model = KNeighborsClassifier(n_neighbors=k, algorithm=algo)\n",
    "    scaler = StandardScaler()\n",
    "    KNC = Pipeline([(\"StandardScaler\", scaler), (\"KNeighborsClassifier\", model)])\n",
    "    KNC.fit(x_train, y_train)\n",
    "    prediction = KNC.predict(X=x_test)\n",
    "    end_time = time.time()\n",
    "    print(\"k = \", k)\n",
    "    print(\"algorithm is \", algo)\n",
    "    print(\"x_test score = \", KNC.score(X=x_test, y=y_test) * 100)\n",
    "    print(\"x_train score = \", KNC.score(X=x_train, y=y_train) * 100)\n",
    "    print(\"time taken = \", end_time - start_time)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 RNC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm is  brute\n",
      "x_test score =  72.72727272727273\n",
      "x_train score =  68.52886405959032\n",
      "time taken =  0.005442619323730469\n",
      "\n",
      "\n",
      "algorithm is  kd_tree\n",
      "x_test score =  72.72727272727273\n",
      "x_train score =  68.52886405959032\n",
      "time taken =  0.0059680938720703125\n",
      "\n",
      "\n",
      "algorithm is  ball_tree\n",
      "x_test score =  72.72727272727273\n",
      "x_train score =  68.52886405959032\n",
      "time taken =  0.0057218074798583984\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "algorithms = [\"brute\", \"kd_tree\", \"ball_tree\"]\n",
    "\n",
    "for algo in algorithms:\n",
    "    start_time = time.time()\n",
    "    model = RadiusNeighborsClassifier(radius=4, algorithm=algo)\n",
    "    scaler = StandardScaler()\n",
    "    RNC = Pipeline([(\"StandardScaler\", scaler), (\"KNeighborsClassifier\", model)])\n",
    "    RNC.fit(x_train, y_train)\n",
    "    prediction = RNC.predict(X=x_test)\n",
    "    end_time = time.time()\n",
    "    print(\"algorithm is \", algo)\n",
    "    print(\"x_test score = \", RNC.score(X=x_test, y=y_test) * 100)\n",
    "    print(\"x_train score = \", RNC.score(X=x_train, y=y_train) * 100)\n",
    "    print(\"time taken = \", end_time - start_time)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffrent between algorithms\n",
    "\n",
    "### 1) Brute Force\n",
    "\n",
    "apply Brute Force technique which search in all dataset point for each query, and get the knn\n",
    "\n",
    "time\n",
    "\n",
    "    O(n * q * m)\n",
    "\n",
    "Efficient brute-force neighbors searches can be very competitive for small data samples\n",
    "\n",
    "### 2) K-D Tree\n",
    "\n",
    "developed to improve brute-force approach, which use BST data structures, to search in it, which is faster than linear search\n",
    "\n",
    "time\n",
    "\n",
    "    O(n * q * log(m))\n",
    "\n",
    "Though the KD tree approach is very fast for low-dimensional (n < 20)\n",
    "when n increased the KD tree approach becomes slow\n",
    "\n",
    "### 3) Ball Tree\n",
    "\n",
    "To address the inefficiencies of KD Trees in higher dimensions, the ball tree data structure was developed. Where KD trees partition data along Cartesian axes, ball trees partition data in a series of nesting hyper-spheres. This makes tree construction more costly than that of the KD tree, but results in a data structure which can be very efficient on highly structured data, even in very high dimensions.\n",
    "\n",
    "A ball tree recursively divides the data into nodes defined by a centroid C and radius r, such that each point in the node lies within the hyper-sphere defined by r and C . The number of candidate points for a neighbor search is reduced through use of the triangle inequality.\n",
    "\n",
    "time\n",
    "\n",
    "    O(n * q * log(m))\n",
    "\n",
    "but it works efficiently with large number of features\n",
    "\n",
    "#### in general choosing the algorithm is important to can control the time of execution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighborhood Components Analysis\n",
    "\n",
    "NCA is used for for classification because it can naturally handle multi-class problems without any increase in the model size, and does not introduce additional parameters that require fine-tuning by the user.\n",
    "\n",
    "NCA classification work well in practice for data sets of varying size and difficulty\n",
    "\n",
    "space complexity\n",
    "\n",
    "    n_samples^2\n",
    "\n",
    "time :\n",
    "\n",
    "    O(n_components x n_samples x min(n_samples, n_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNC with NCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  23\n",
      "algorithm is  brute\n",
      "x_test score =  74.45887445887446\n",
      "x_train score =  77.28119180633148\n",
      "time taken =  0.9841864109039307\n",
      "\n",
      "\n",
      "k =  23\n",
      "algorithm is  kd_tree\n",
      "x_test score =  74.45887445887446\n",
      "x_train score =  77.28119180633148\n",
      "time taken =  0.9245028495788574\n",
      "\n",
      "\n",
      "k =  23\n",
      "algorithm is  ball_tree\n",
      "x_test score =  74.45887445887446\n",
      "x_train score =  77.28119180633148\n",
      "time taken =  0.9991514682769775\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "algorithms = [\"brute\", \"kd_tree\", \"ball_tree\"]\n",
    "\n",
    "for algo in algorithms:\n",
    "    start_time = time.time()\n",
    "    k = int(math.sqrt(len(x_train)))\n",
    "    if not (k & 1):\n",
    "        k += 1\n",
    "    model = KNeighborsClassifier(n_neighbors=k, algorithm=algo)\n",
    "    scaler = StandardScaler()\n",
    "    NCA = NeighborhoodComponentsAnalysis()\n",
    "    KNC = Pipeline(\n",
    "        [\n",
    "            (\"StandardScaler\", scaler),\n",
    "            (\"NeighborhoodComponentsAnalysis\", NCA),\n",
    "            (\"KNeighborsClassifier\", model),\n",
    "        ]\n",
    "    )\n",
    "    KNC.fit(x_train, y_train)\n",
    "    prediction = KNC.predict(X=x_test)\n",
    "    end_time = time.time()\n",
    "    print(\"k = \", k)\n",
    "    print(\"algorithm is \", algo)\n",
    "    print(\"x_test score = \", KNC.score(X=x_test, y=y_test) * 100)\n",
    "    print(\"x_train score = \", KNC.score(X=x_train, y=y_train) * 100)\n",
    "    print(\"time taken = \", end_time - start_time)\n",
    "    print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
